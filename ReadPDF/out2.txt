FFTW AN ADAPTIVE SOFTWARE ARCHITECTURE FOR THE FFT Matteo Frigo MIT Laboratory for Computer Science 545 Technology Square NE43-203 Cambridge MA 02139 athena@theory lcs mit Steven G Johnson Massachusetts Institute of Technology 77 Massachusetts Avenue 12-104 Cambridge MA 02139 stevenj@alum mit ABSTRACT FFT literature has mostly concerned with minimizing the number of floating-point operations performed algorithm Unfortunately on present-day microprocessors this measure is far less important than it used to interactions with the pro- cessor pipeline the memory hierarchy have larger impact on performance Consequently one must know the details of architecture in order to design fast algorithm In this paper we propose adaptive FFT program that tunes the com- putation automatically for particular hardware We compared our program called FFTW with over 40 implementations of the FFT on 7 machines Our tests show that FFTW’s self-optimizing approach usually yields significantly performance than other publicly software FFTW compares favorably with machine-specific vendor-optimized libraries 1 INTRODUCTION The discrete Fourier transform (DFT) is important tool in many branches of science engineering [1] has studied ex- tensively [2] For many practical applications it is important to have implementation of the DFT that is fast possible In the past speed was the direct consequence of clever algorithms [2] that minimized the number of arithmetic operations On present- day general-purpose microprocessors however the performance of program is mostly determined complicated interactions of the code with the processor pipeline the structure of the memory Designing for performance under these conditions re- quires intimate knowledge of the architecture In this paper we address this problem means of novel adaptive ap- proach where the program itself adapts the computation to the de- tails of the hardware We developed FFTW adaptive high per- formance implementation of the Cooley-Tukey fast Fourier trans- form (FFT) algorithm [3] written in C We have compared many C Fortran implementations of the DFT on several machines our experiments show that FFTW typically yields significantly performance than other publicly DFT software More interestingly while retaining complete portability FFTW is competitive with or faster than proprietary codes such Sun’s Per- formance Library IBM’s ESSL library that highly tuned for single machine Such encouraging results raise the hope that Matteo Frigo was supported in part the Defense Advanced Re- search Projects Agency (DARPA) under Grant N00014-94-1-0985 Digital Equipment Corporation Fellowship Steven G Johnson was sup- ported in part DoD NDSEG Fellowship MIT Karl Taylor Compton Fellowship the Materials Research Science Engineering Center program of the National Science Foundation under award DMR-9400334 fftw_plan plan COMPLEX A[n] B[n] /* plan the computation */ plan = fftw_create_plan(n) /* execute the plan */ fftw(plan A) /* the plan reused for other inputs of size N */ fftw(plan B) Figure 1 Simplified example of FFTW’s use The user must first create plan which then used will similar adaptive techniques applied successfully to other problems In FFTW the computation of the transform is accomplished executor that consists of highly optimized composable blocks of C code called codelets A codelet is specialized piece of code that computes part of the transform The combination of codelets applied the executor is specified special data structure called plan The plan is determined runtime the com- putation begins planner which uses dynamic programming algorithm [4 chapter 16] to find fast composition of codelets The planner tries to minimize the actual execution time not the number of floating point operations since we show in Sec- tion 2 there there is little correlation these two perfor- mance measures Consequently the planner measures the run time of many plans selects the fastest In the current implementa- tion plans saved to disk used later time The speed of the executor depends crucially on the efficiency of the codelets writing optimizing them is tedious error-prone process For this reason we found it convenient to generate the codelets automatically means of special-purpose compiler FFTW’s codelet generator written in the Caml Light dialect of the functional language ML [5] is sophisticated pro- gram that first produces representation of the codelet in the form of abstract C syntax tree then “optimizes” the codelet ap- plying well known transformations such constant folding algebraic identities The main advantages of generating code that it is simple to experiment with algorithms or coding strategies it is easy to produce many long blocks of unrolled optimized code FFTW’s internal complexity is not visible to the user how- ever The user interacts with FFTW only through the planner the executor (See Figure 1 ) The codelet generator is not used compile time the user not need to know Caml Light or have Caml Light compiler FFTW provides function that creates plan for transform of specified size once the plan has created it used many times needed The FFTW library (currently version 1 2) is publicly avail- our WWW page [6] FFTW is not toy system production-quality library that enjoys many hundreds of users FFTW performs one- multidimensional transforms it is not restricted to input sizes that powers of 2 A parallel version of the executor written in Cilk [7] exists The rest of the paper is organized follows In Section 2 we outline the runtime structure of FFTW consisting of the executor the planner In Section 3 we briefly the compile-time structure of FFTW—that is the codelet generator In Section 4 we present part of the performance measurements we collected the development of FFTW Finally in Section 5 we give some concluding remarks 2 FFTW’S RUNTIME STRUCTURE In this section we the executor which is the part of FFTW that computes the transform We discuss how FFTW builds plan (a sequence of instructions that specifies the opera- tion of the executor) Finally we present evidence that FFTW’s adaptive architecture is good idea The executor implements the Cooley-Tukey FFT algorithm [3] which centers factoring the size N of the transform into N = N1N2 The algorithm recursively computes N1 trans- forms of size N2 multiplies the results constants tradi- tionally called twiddle factors finally computesN2 transforms of size N1 The executor consists of C function that implements the algorithm just outlined of library of codelets that imple- ment special cases of the Cooley-Tukey algorithm Specifically codelets in two flavors Normal codelets compute the DFT of fixed size used the base case for the recursion Twiddle codelets like normal codelets in addition they mul- tiply their input the twiddle factors Twiddle codelets used for the internal levels of the recursion The current FFTW release codelets for the integers up to 16 the powers of2 up to 64 covering wide spectrum of practical applications The executor takes input the array to transformed plan which is data structure that specifies the factorization of N well which codelets should used For example here is high-level description of possible plan for transform of length N = 128 DIVIDE-AND-CONQUER(128 4) DIVIDE-AND-CONQUER(32 8) SOLVE(4) In response to this plan the executor initially computes 4 trans- forms of size 32 recursively then uses the twiddle codelet of size 4 to combine the results of the subproblems In the same way the problems of size 32 divided into 8 problems of size 4 which solved directly using normal codelet (as specified the last line of the plan) then combined using size-8 twid- dle codelet The executor works explicit recursion in contrast with the traditional loop-based implementations [1 page 608] We chose explicitly recursive implementation of theoretical ev- idence that divide-and-conquer algorithms improve locality [8] For example soon subproblem fits into the cache no fur- ther cache misses needed in order to solve that subproblem We E E E E E E EE E E E E 30 40 50 60 70 80 90 17 90 00 0 18 00 00 0 18 10 00 0 18 20 00 0 18 30 00 0 18 40 00 0 18 50 00 0 18 60 00 0 Sp ee in “ M FL O PS ” Floating Point Operations worst Figure 2 Speeds vs flops of various plans considered the planner for N = 32768 The units of speed (“MFLOPS”) the machine in Section 4 Notice that the fastest plan is not the one that performs the fewest operations have not yet determined experimentally the relative advantages of the loop-based recursive approaches however Since codelet performs significant of work the overhead of the recur- sion is negligible Moreover recursion is easier to code codelets to perform well defined task that is independent of the context in which the codelet is used How one construct good plan FFTW’s strategy is to measure the execution time of many plans to select the Ideally FFTW’s planner should try possible plans This ap- proach however is not practical to the combinatorial explo- sion of the number of plans Instead the planner uses dynamic- programming algorithm [4 chapter 16] to prune the search space In order to use dynamic-programming we assumed optimal sub- structure [4] if optimal plan for size N is known this plan is still optimal when size N is used subproblem of larger trans- form This assumption is in principle false of the states of the cache in the two cases In practice we tried approaches the simplifying hypothesis yielded good results In order to demonstrate the importance of the planner well the difficulty of predicting the optimal plan in Figure 2 we show the speed of various plans (measured reported in Section 4) function of the number of floating point operations (flops) re- quired plan (The planner computes exact count of the operations ) There two important phenomena that we observe in this graph First compositions of the codelets result in wide range of performance it is important to choose the right combination Second the total number of flops is inade- quate predictor of the execution time least for the relatively small variations in the flops that obtain for given N We have found that the optimal plan depends heavily on the processor the memory architecture the compiler For exam- ple for double-precision complex transforms N = 1024 is fac- tored into 1024 = 8  8  16 on UltraSPARC into 1024 =32  32 on Alpha We have no theory that predicts the optimal plan other than some heuristic rules of the form “radix X seems to work on machine Y ” 3 THE CODELET GENERATOR In this section we the codelet generator which produces optimized fragments of C code (“codelets”) specialized to com- pute the transform of fixed size In the limited space we shall try to give the reader flavor of how the generator works why such tool is important let simplify_times = fun (Real a) (Real b) -> (Real (a * b)) | (Real a) -> if (almost_equal 0 0) then (Real 0 0) if (almost_equal 1 0) then if (almost_equal (-1 0)) then simplify (Uminus b) Times ((Real a) b) Figure 3 Example of the rules that constitute the optimizer The function shown in the figure simplifies the product of two factors If factors real numbers the optimizer replaces the multi- plication single real number Multiplications constants simplified when the constant is 0 1 or 1 The actual generator other rules that not shown here The codelet generator accepts input integer N pro- duces normal or twiddle codelet that computes the Fourier transform of size N (either the forward or backward transform) The generator is written in the Caml Light dialect of ML [5] Caml is applicative polymorphic strongly typed functional lan- guage with first-class functions algebraic data types pattern matching The generator operates on subset of the abstract syntax tree (AST) of the C language First the generator produces AST for na ve program that computes the transform Then it applies local optimizations to the AST in order to improve the program Finally it unparses the AST to produce the desired C code The AST generation phase creates crude AST for the desired codelet This AST some useless code such multipli- cations 0 1 the code is polished the following opti- mization phase The current version of the AST generator knowledge of many DFT algorithms including Cooley-Tukey (in the form presented in [1 page 611]) prime factor algorithm (as in [1 page 619]) split-radix algorithm [2] Rader’s algorithm for transforms of prime length [9] Our first implemen- tation of the Cooley-Tukey AST generator consisted of 60 lines of Caml code The prime factor split-radix algorithms were added using 20 additional lines of code (To avoid confusion it is worth remarking that the codelet generator uses variety of algorithms for producing codelets the executor is only capable of composing codelets to the Cooley-Tukey algorithm ) The AST generator builds the syntax tree recursively At stage of the recursion several algorithms applicable it is not clear which one should used The AST generator chooses the algorithm that minimizes cost function which depends on the arithmetic complexity of the codelet its memory traf- fic Experimentally we achieved the results minimizing the function 4v+ f where v is the number of stack variables gen- erated f is the number of floating-point operations (The co- efficient 4 is not critical ) This choice of the cost function yielded typical improvement of 20% over our first generator that just implemented radix-2 Cooley-Tukey Typically with this func- tion if the prime factor algorithm is not applicable the generator tends to use radix- pN Cooley-Tukey algorithm The optimizer transforms raw AST into equivalent one that executes much faster The optimizer consists of set of rules that applied locally to nodes of the AST A fragment of the optimizer appears in Figure 3 The example shows that the pattern- matching features of Caml useful for writing the optimizer B B B B B B B B B B B B B B B B B B J J J J J J J J J J J J J J J J J J H H H H H H H H H H H H H H H H H H F F F F F F F F F F F F F F F F Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ Ñ É É É É É É É É É É É É É É É É É ÉÇ Ç Ç Ç Ç Ç Ç Ç Ç Ç Ç Ç Å Å Å Å Å Å Å Å Å Å Å Å Å Å Å Å Å Å M M M M M M M M M M M M M M M M M M 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 á á á á á á á á á á á á á á á Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü Ü 2 4 8 16 32 64 12 8 25 6 51 2 10 24 20 48 40 96 81 92 16 38 4 32 76 8 65 53 6 13 10 72 26 21 44 0 50 100 15 
